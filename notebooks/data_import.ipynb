{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GEM Data Hackathon - Data Import and Processing\n",
    "This notebook converts the original R code for data processing into Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import gc\n",
    "\n",
    "# Clear memory (Python equivalent of rm(list = ls()) in R)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15868 entries, 0 to 15867\n",
      "Data columns (total 19 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   weight                     15868 non-null  float64\n",
      " 1   new_entrepreneur           15868 non-null  object \n",
      " 2   established_entrepreneur   15868 non-null  object \n",
      " 3   knows_entrepreneur         15761 non-null  object \n",
      " 4   local_opportunity          13316 non-null  object \n",
      " 5   entrepreneurial_skill      14795 non-null  object \n",
      " 6   fear_of_failure            15120 non-null  object \n",
      " 7   wants_entrepreneurship     12070 non-null  object \n",
      " 8   respects_entrepreneurship  12082 non-null  object \n",
      " 9   follows_entrepreneurship   12417 non-null  object \n",
      " 10  future_startup             15420 non-null  object \n",
      " 11  discontinued_business      15827 non-null  object \n",
      " 12  is_investor                15820 non-null  object \n",
      " 13  gender                     15868 non-null  object \n",
      " 14  age_range                  15868 non-null  object \n",
      " 15  household_size             15563 non-null  float64\n",
      " 16  year                       15868 non-null  int64  \n",
      " 17  race                       12630 non-null  object \n",
      " 18  region                     15868 non-null  object \n",
      "dtypes: float64(2), int64(1), object(16)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "# Note: Adjust the file path as needed for your system\n",
    "data = pd.read_csv(\"/Users/connorraney/gem-data-hackathon/Hackathon_GEM_Data.csv\")\n",
    "\n",
    "# Display basic info about the dataset\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to recode all variables to their labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recode_data_labels(data):\n",
    "    # Create a copy of the original data\n",
    "    data_labeled = data.copy()\n",
    "    \n",
    "    # recode gender\n",
    "    data_labeled['gender'] = pd.Categorical(\n",
    "        data['gender'],\n",
    "        categories=[1, 2],\n",
    "        ordered=False\n",
    "    ).rename_categories({1: 'male', 2: 'female'})\n",
    "    \n",
    "    # recode age range\n",
    "    data_labeled['age9c'] = pd.Categorical(\n",
    "        data['age9c'], \n",
    "        categories=[2, 3, 4, 5, 6, 7],\n",
    "        ordered=True\n",
    "    ).rename_categories({2: '18-24', 3: '25-34', 4: '35-44', 5: '45-54', 6: '55-64', 7: '65-74'})\n",
    "    \n",
    "    # recode household size (special case with numeric values to preserve)\n",
    "    data_labeled['hhsize'] = data['hhsize'].apply(lambda x: \n",
    "        'Refused' if x == -2 else \n",
    "        \"Don't know\" if x == -1 else \n",
    "        str(x) if 1 <= x <= 44 else \n",
    "        np.nan\n",
    "    )\n",
    "    \n",
    "    # recode income brackets\n",
    "    income_levels = {\n",
    "        1: 'Under $15,000',\n",
    "        2: '$15,000 to under $25,000',\n",
    "        3: '$25,000 to under $35,000',\n",
    "        4: '$35,000 to under $50,000',\n",
    "        5: '$50,000 to under $75,000',\n",
    "        6: '$75,000 to under $100,000',\n",
    "        7: '$100,000 to under $150,000',\n",
    "        8: '$150,000 to under $200,000',\n",
    "        9: 'Over $200,000'\n",
    "    }\n",
    "    data_labeled['ushhinc'] = pd.Categorical(\n",
    "        data['ushhinc'], \n",
    "        categories=list(income_levels.keys()),\n",
    "        ordered=True\n",
    "    ).rename_categories(income_levels)\n",
    "    \n",
    "    # recode education level\n",
    "    education_levels = {\n",
    "        1: 'None/Less than High School',\n",
    "        2: 'Some High School',\n",
    "        3: 'Completed High School',\n",
    "        4: 'Some College/University',\n",
    "        5: 'Completed College/University',\n",
    "        6: 'Degree Graduate (Master\\'s or PhD)'\n",
    "    }\n",
    "    data_labeled['usreduc'] = pd.Categorical(\n",
    "        data['usreduc'], \n",
    "        categories=list(education_levels.keys()),\n",
    "        ordered=True\n",
    "    ).rename_categories(education_levels)\n",
    "    \n",
    "    # recode race\n",
    "    race_levels = {\n",
    "        -2: 'Refused', \n",
    "        -1: \"Don't know\", \n",
    "        1: 'White', \n",
    "        2: 'Black', \n",
    "        3: 'Hispanic', \n",
    "        4: 'Other'\n",
    "    }\n",
    "    data_labeled['race'] = pd.Categorical(\n",
    "        data['race'], \n",
    "        categories=list(race_levels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(race_levels)\n",
    "    \n",
    "    # recode region\n",
    "    region_levels = {\n",
    "        1: 'New England',\n",
    "        2: 'New York-New Jersey',\n",
    "        3: 'Mid-Atlantic',\n",
    "        4: 'Southeast',\n",
    "        5: 'Great Lakes',\n",
    "        6: 'South',\n",
    "        7: 'Central Midwest',\n",
    "        8: 'Mountain and Plains',\n",
    "        9: 'Pacific Southwest',\n",
    "        10: 'Pacific Northwest'\n",
    "    }\n",
    "    data_labeled['region'] = pd.Categorical(\n",
    "        data['region'], \n",
    "        categories=list(region_levels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(region_levels)\n",
    "    \n",
    "    # recode variables with standard Yes/No patterns\n",
    "    yes_no_vars = [\n",
    "        \"knowent\", \"opport\", \"suskill\", \"fearfail\", \"nbgoodc\", \"nbstatus\", \n",
    "        \"nbmedia\", \"TEA\", \"ESTBBUSO\", \"futsup\", \"discent\", \"busang\"\n",
    "    ]\n",
    "    \n",
    "    for var in yes_no_vars:\n",
    "        if var in data.columns:\n",
    "            data_labeled[var] = pd.Categorical(\n",
    "                data[var],\n",
    "                categories=[-2, -1, 0, 1],\n",
    "                ordered=False\n",
    "            ).rename_categories({-2: 'Refused', -1: \"Don't know\", 0: 'No', 1: 'Yes'})\n",
    "    \n",
    "    # recode TEANEWPR\n",
    "    data_labeled['TEANEWPR'] = pd.Categorical(\n",
    "        data['TEANEWPR'],\n",
    "        categories=[-2, -1, 1, 2],\n",
    "        ordered=False\n",
    "    ).rename_categories({-2: 'Refused', -1: \"Don't know\", 1: 'Yes', 2: 'No'})\n",
    "    \n",
    "    # recode TEANEWPROD\n",
    "    new_prod_levels = {\n",
    "        -2: 'Refused',\n",
    "        -1: \"Don't know\",\n",
    "        1: 'No, not new product or service',\n",
    "        2: 'New to people in the area where you live',\n",
    "        3: 'New to people in your country',\n",
    "        4: 'New to the world'\n",
    "    }\n",
    "    data_labeled['TEANEWPROD'] = pd.Categorical(\n",
    "        data['TEANEWPROD'],\n",
    "        categories=list(new_prod_levels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(new_prod_levels)\n",
    "    \n",
    "    # recode TEAEXP4C\n",
    "    tea_exp_levels = {\n",
    "        -2: 'Refused',\n",
    "        -1: \"Don't know\",\n",
    "        1: 'More than 75%',\n",
    "        2: '25 to 75%',\n",
    "        3: 'Under 25%',\n",
    "        4: 'None'\n",
    "    }\n",
    "    data_labeled['TEAEXP4C'] = pd.Categorical(\n",
    "        data['TEAEXP4C'],\n",
    "        categories=list(tea_exp_levels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(tea_exp_levels)\n",
    "    \n",
    "    # recode EB_EXP4C\n",
    "    eb_exp_levels = {\n",
    "        -2: 'Refused',\n",
    "        -1: \"Don't know\",\n",
    "        5: 'More than 75%',\n",
    "        6: '25 to 75%',\n",
    "        7: 'Under 25%',\n",
    "        8: 'None'\n",
    "    }\n",
    "    data_labeled['EB_EXP4C'] = pd.Categorical(\n",
    "        data['EB_EXP4C'],\n",
    "        categories=list(eb_exp_levels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(eb_exp_levels)\n",
    "    \n",
    "    # recode industry classifications (both TEA and EB use same coding)\n",
    "    industry_labels = {\n",
    "        -2: 'NOT CLASSIFIED/MISSING',\n",
    "        1: 'AGRICULTURE,FORESTRY,FISHING',\n",
    "        2: 'MINING,CONSTRUCTION',\n",
    "        3: 'MANUFACTURING',\n",
    "        4: 'UTILISATION, TRANSPORT, STORAGE',\n",
    "        5: 'WHOLESALE TRADE',\n",
    "        6: 'RETAIL TRADE, HOTELS & RESTAURANTS',\n",
    "        7: 'INFORMATION AND COMMUNICATION',\n",
    "        8: 'FINANCIAL INTERMEDIATION, REAL ESTATE',\n",
    "        9: 'PROFESSIONAL SERVICES',\n",
    "        10: 'ADMINISTRATIVE SERVICES',\n",
    "        11: 'GOVERNMENT, HEALTH, EDUCATION, SOCIAL SERVICES',\n",
    "        12: 'PERSONAL/CONSUMER SERVICE ACTIVITIES'\n",
    "    }\n",
    "    \n",
    "    data_labeled['TEAISIC4_1D'] = pd.Categorical(\n",
    "        data['TEAISIC4_1D'],\n",
    "        categories=list(industry_labels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(industry_labels)\n",
    "    \n",
    "    data_labeled['EB_ISIC4_1D'] = pd.Categorical(\n",
    "        data['EB_ISIC4_1D'],\n",
    "        categories=list(industry_labels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(industry_labels)\n",
    "    \n",
    "    # recode exbuscon\n",
    "    exbuscon_levels = {\n",
    "        -2: 'Refused',\n",
    "        -1: \"Don't know\",\n",
    "        1: 'Yes',\n",
    "        2: 'No',\n",
    "        3: 'Business continued but activities changed'\n",
    "    }\n",
    "    data_labeled['exbuscon'] = pd.Categorical(\n",
    "        data['exbuscon'],\n",
    "        categories=list(exbuscon_levels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(exbuscon_levels)\n",
    "    \n",
    "    # recode bafund\n",
    "    bafund_levels = {\n",
    "        -3: 'Have not provided funds',\n",
    "        -2: 'Refused',\n",
    "        -1: \"Don't know\"\n",
    "    }\n",
    "    data_labeled['bafund'] = pd.Categorical(\n",
    "        data['bafund'],\n",
    "        categories=list(bafund_levels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(bafund_levels)\n",
    "    \n",
    "    # recode barel\n",
    "    barel_levels = {\n",
    "        -2: 'Refused',\n",
    "        -1: \"Don't know\",\n",
    "        1: 'Close family member, such as a spouse, brother, child, parent, or grandchild',\n",
    "        2: 'Some other relative, kin, or blood relation',\n",
    "        3: 'A work colleague',\n",
    "        4: 'A friend or neighbor, or',\n",
    "        5: 'A stranger with a good business idea',\n",
    "        6: 'Other'\n",
    "    }\n",
    "    data_labeled['barel'] = pd.Categorical(\n",
    "        data['barel'],\n",
    "        categories=list(barel_levels.keys()),\n",
    "        ordered=False\n",
    "    ).rename_categories(barel_levels)\n",
    "    \n",
    "    return data_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'age9c'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/gem-data-hackathon/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3804\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3805\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3806\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mindex.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'age9c'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Apply the function to the dataset\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m data = \u001b[43mrecode_data_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Display the first few rows of the recoded data\u001b[39;00m\n\u001b[32m      5\u001b[39m data.head()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36mrecode_data_labels\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m      6\u001b[39m data_labeled[\u001b[33m'\u001b[39m\u001b[33mgender\u001b[39m\u001b[33m'\u001b[39m] = pd.Categorical(\n\u001b[32m      7\u001b[39m     data[\u001b[33m'\u001b[39m\u001b[33mgender\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m      8\u001b[39m     categories=[\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m],\n\u001b[32m      9\u001b[39m     ordered=\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     10\u001b[39m ).rename_categories({\u001b[32m1\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mmale\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m2\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mfemale\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# recode age range\u001b[39;00m\n\u001b[32m     13\u001b[39m data_labeled[\u001b[33m'\u001b[39m\u001b[33mage9c\u001b[39m\u001b[33m'\u001b[39m] = pd.Categorical(\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     \u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mage9c\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m, \n\u001b[32m     15\u001b[39m     categories=[\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m],\n\u001b[32m     16\u001b[39m     ordered=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     17\u001b[39m ).rename_categories({\u001b[32m2\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m18-24\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m3\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m25-34\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m4\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m35-44\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m5\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m45-54\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m6\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m55-64\u001b[39m\u001b[33m'\u001b[39m, \u001b[32m7\u001b[39m: \u001b[33m'\u001b[39m\u001b[33m65-74\u001b[39m\u001b[33m'\u001b[39m})\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# recode household size (special case with numeric values to preserve)\u001b[39;00m\n\u001b[32m     20\u001b[39m data_labeled[\u001b[33m'\u001b[39m\u001b[33mhhsize\u001b[39m\u001b[33m'\u001b[39m] = data[\u001b[33m'\u001b[39m\u001b[33mhhsize\u001b[39m\u001b[33m'\u001b[39m].apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \n\u001b[32m     21\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mRefused\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x == -\u001b[32m2\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \n\u001b[32m     22\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mDon\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt know\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m x == -\u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \n\u001b[32m     23\u001b[39m     \u001b[38;5;28mstr\u001b[39m(x) \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m1\u001b[39m <= x <= \u001b[32m44\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \n\u001b[32m     24\u001b[39m     np.nan\n\u001b[32m     25\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/gem-data-hackathon/lib/python3.12/site-packages/pandas/core/frame.py:4102\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4101\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4102\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4103\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4104\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.virtualenvs/gem-data-hackathon/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3807\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3808\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3809\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3810\u001b[39m     ):\n\u001b[32m   3811\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3814\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3815\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3816\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3817\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'age9c'"
     ]
    }
   ],
   "source": [
    "# Apply the function to the dataset\n",
    "data = recode_data_labels(data)\n",
    "\n",
    "# Display the first few rows of the recoded data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace \"Refused\" and \"Don't know\" values with NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of variables to clean\n",
    "variables_to_clean = [\n",
    "    'knowent', 'opport', 'suskill', 'fearfail', 'nbgoodc', 'nbstatus', 'nbmedia',\n",
    "    'futsup', 'discent', 'exbuscon', 'busang', 'barel', 'ESTBBUSO', 'TEAEXP4C',\n",
    "    'EB_EXP4C', 'TEANEWPR', 'TEANEWPROD', 'TEA', 'race'\n",
    "]\n",
    "\n",
    "# Replace \"Refused\" and \"Don't know\" with NaN for each variable\n",
    "for var in variables_to_clean:\n",
    "    if var in data.columns:\n",
    "        # Check if the variable is categorical\n",
    "        if pd.api.types.is_categorical_dtype(data[var]):\n",
    "            # Create a mask for values to replace with NaN\n",
    "            mask = data[var].isin(['Refused', \"Don't know\"])\n",
    "            # Convert to string to handle NaN assignment\n",
    "            data.loc[mask, var] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert specific columns to appropriate data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert columns to integer where needed\n",
    "# First replace non-numeric strings with NaN\n",
    "data['hhsize'] = pd.to_numeric(data['hhsize'], errors='coerce')\n",
    "\n",
    "# Convert other columns to integers\n",
    "int_columns = ['TEAJOBGR', 'EB_JOBGR', 'EB_OWNER', 'TEAOWNER', 'EB_JOBNOW', 'TEAJOBNOW']\n",
    "for col in int_columns:\n",
    "    if col in data.columns:\n",
    "        data[col] = pd.to_numeric(data[col], errors='coerce').astype('Int64')  # Int64 handles NaN values\n",
    "\n",
    "# Convert yrsurv to category\n",
    "if 'yrsurv' in data.columns:\n",
    "    data['yrsurv'] = data['yrsurv'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename and reorder columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns - first put WEIGHT_L, TEA, ESTBBUSO at the beginning\n",
    "columns = ['WEIGHT_L', 'TEA', 'ESTBBUSO'] + [col for col in data.columns if col not in ['WEIGHT_L', 'TEA', 'ESTBBUSO']]\n",
    "data = data[columns]\n",
    "\n",
    "# Rename columns\n",
    "column_mapping = {\n",
    "    'yrsurv': 'year',\n",
    "    'gender': 'gender',\n",
    "    'age9c': 'age_range',\n",
    "    'hhsize': 'household_size',\n",
    "    'ushhinc': 'household_income',\n",
    "    'usreduc': 'education',\n",
    "    'race': 'race',\n",
    "    'region': 'region',\n",
    "    'knowent': 'knows_entrepreneur',\n",
    "    'opport': 'local_opportunity',\n",
    "    'suskill': 'entrepreneurial_skill',\n",
    "    'fearfail': 'fear_of_failure',\n",
    "    'nbgoodc': 'wants_entrepreneurship',\n",
    "    'nbstatus': 'respects_entrepreneurship',\n",
    "    'nbmedia': 'follows_entrepreneurship',\n",
    "    'TEA': 'new_entrepreneur',\n",
    "    'ESTBBUSO': 'established_entrepreneur',\n",
    "    'TEAOWNER': 'new_entrepreneur_owners',\n",
    "    'EB_OWNER': 'established_entrepreneur_owners',\n",
    "    'TEAJOBNOW': 'new_entrepreneur_employees',\n",
    "    'EB_JOBNOW': 'established_entrepreneur_employees',\n",
    "    'TEAJOBGR': 'new_entrepreneur_new_jobs',\n",
    "    'EB_JOBGR': 'established_entrepreneur_new_jobs',\n",
    "    'TEANEWPR': 'new_entrepreneur_innovation',\n",
    "    'TEANEWPROD': 'new_entrepreneur_local_innovation',\n",
    "    'TEAEXP4C': 'new_entrepreneur_external_sales',\n",
    "    'EB_EXP4C': 'established_entrepreneur_external_sales',\n",
    "    'TEAISIC4_1D': 'new_entrepreneur_industry',\n",
    "    'EB_ISIC4_1D': 'established_entrepreneur_industry',\n",
    "    'futsup': 'future_startup',\n",
    "    'discent': 'discontinued_business',\n",
    "    'exbuscon': 'discontinued_business_continuation',\n",
    "    'busang': 'is_investor',\n",
    "    'bafund': 'investment',\n",
    "    'barel': 'investment_relationship',\n",
    "    'WEIGHT_L': 'weight'\n",
    "}\n",
    "\n",
    "# Rename only columns that exist in the dataframe\n",
    "existing_columns = {k: v for k, v in column_mapping.items() if k in data.columns}\n",
    "data = data.rename(columns=existing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove mostly empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop\n",
    "columns_to_drop = [\n",
    "    'discontinued_business_continuation', 'investment', 'new_entrepreneur_local_innovation',\n",
    "    'investment_relationship', 'household_income', 'education', 'new_entrepreneur_industry',\n",
    "    'established_entrepreneur_industry', 'new_entrepreneur_new_jobs', 'established_entrepreneur_new_jobs',\n",
    "    'new_entrepreneur_owners', 'established_entrepreneur_owners', 'new_entrepreneur_external_sales',\n",
    "    'established_entrepreneur_external_sales', 'new_entrepreneur_innovation', 'new_entrepreneur_employees',\n",
    "    'established_entrepreneur_employees'\n",
    "]\n",
    "\n",
    "# Drop only columns that exist in the dataframe\n",
    "existing_columns_to_drop = [col for col in columns_to_drop if col in data.columns]\n",
    "data = data.drop(columns=existing_columns_to_drop)\n",
    "\n",
    "# Display data info after cleaning\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data\n",
    "data.to_csv('Hackathon_GEM_Data_Python.csv', index=False)\n",
    "print(\"Data saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gem-data-hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
